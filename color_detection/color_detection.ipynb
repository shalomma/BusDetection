{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_CSV = '../annotations/annotationsTrain.csv'\n",
    "PATH_TO_IMAGES = '../images/'\n",
    "PATH_TO_CROPPED = '../images/cropped/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PATH_TO_CSV)\n",
    "grouped = df.groupby('filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\alloc.cpp:55: error: (-4) Failed to allocate 29942784 bytes in function cv::OutOfMemoryError\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-cf2e690eae5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrouped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPATH_TO_IMAGES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;31m#img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\alloc.cpp:55: error: (-4) Failed to allocate 29942784 bytes in function cv::OutOfMemoryError\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j = 0 \n",
    "cropped = []\n",
    "for k, g in zip(grouped.groups.keys(), grouped.groups):\n",
    "    img = cv.imread(os.path.join(PATH_TO_IMAGES, g))\n",
    "    #img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    for idx, row in grouped.get_group(g).iterrows():\n",
    "        temp = img[row['ymin']:row['ymax'], row['xmin']:row['xmax']]\n",
    "        cropped.append((temp,row['class']))\n",
    "        path = os.path.join(PATH_TO_IMAGES, 'cropped/{}_pic.JPG'.format(j))\n",
    "        j = j + 1\n",
    "        cv.imwrite(path, temp)\n",
    "    if (i == 2):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[187, 194, 203],\n",
       "         [189, 196, 205],\n",
       "         [189, 196, 205],\n",
       "         ...,\n",
       "         [221, 213, 213],\n",
       "         [222, 214, 214],\n",
       "         [223, 215, 215]],\n",
       " \n",
       "        [[190, 197, 206],\n",
       "         [191, 198, 207],\n",
       "         [191, 198, 207],\n",
       "         ...,\n",
       "         [220, 212, 212],\n",
       "         [223, 215, 215],\n",
       "         [223, 215, 215]],\n",
       " \n",
       "        [[191, 196, 205],\n",
       "         [190, 197, 206],\n",
       "         [189, 196, 205],\n",
       "         ...,\n",
       "         [219, 211, 211],\n",
       "         [225, 217, 217],\n",
       "         [224, 216, 216]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[215, 210, 212],\n",
       "         [217, 212, 214],\n",
       "         [216, 211, 213],\n",
       "         ...,\n",
       "         [ 96,  92, 128],\n",
       "         [ 76,  72, 107],\n",
       "         [ 65,  61,  96]],\n",
       " \n",
       "        [[214, 209, 211],\n",
       "         [213, 208, 210],\n",
       "         [210, 205, 207],\n",
       "         ...,\n",
       "         [ 55,  50,  89],\n",
       "         [ 50,  45,  84],\n",
       "         [ 43,  40,  79]],\n",
       " \n",
       "        [[213, 208, 210],\n",
       "         [213, 208, 210],\n",
       "         [211, 206, 208],\n",
       "         ...,\n",
       "         [ 56,  52,  93],\n",
       "         [ 57,  53,  95],\n",
       "         [ 50,  46,  88]]], dtype=uint8), 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cropped[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_g = cv.imread(os.path.join(PATH_TO_CROPPED, '0_pic.JPG'))\n",
    "img_g = cv.cvtColor(img_g, cv.COLOR_BGR2RGB)\n",
    "img_r = cv.imread(os.path.join(PATH_TO_CROPPED, '9_pic.JPG'))\n",
    "img_r = cv.cvtColor(img_r, cv.COLOR_BGR2RGB)\n",
    "img_b = cv.imread(os.path.join(PATH_TO_CROPPED, '33_pic.JPG'))\n",
    "img_b = cv.cvtColor(img_b, cv.COLOR_BGR2RGB)\n",
    "plt.figure()\n",
    "plt.imshow(img_g)\n",
    "plt.figure()\n",
    "plt.imshow(img_r)\n",
    "plt.figure()\n",
    "plt.imshow(img_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(np.mean(img_g[0]), np.mean(img_g[1]), np.mean(img_g[2]), c='g', marker='o')\n",
    "ax.scatter(np.mean(img_r[0]), np.mean(img_r[1]), np.mean(img_r[2]), c='r', marker='o')\n",
    "ax.scatter(np.mean(img_b[0]), np.mean(img_b[1]), np.mean(img_b[2]), c='b', marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "from skimage import filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pgmagick as pg\n",
    "\n",
    "def trans_mask_sobel(img):\n",
    "    \"\"\" Generate a transparency mask for a given image \"\"\"\n",
    "\n",
    "    image = pg.Image(img)\n",
    "\n",
    "    # Find object\n",
    "    image.negate()\n",
    "    image.edge()\n",
    "    image.blur(1)\n",
    "    image.threshold(1)\n",
    "    image.adaptiveThreshold(11, 11, 11)\n",
    "\n",
    "    # Fill background\n",
    "    image.fillColor('magenta')\n",
    "    w, h = image.size().width(), image.size().height()\n",
    "    image.floodFillColor('0x0', 'magenta')\n",
    "    #image.floodFillColor('0x0+%s+0' % (w-1), 'magenta')\n",
    "    #image.floodFillColor('0x0+0+%s' % (h-1), 'magenta')\n",
    "    #image.floodFillColor('0x0+%s+%s' % (w-1, h-1), 'magenta')\n",
    "\n",
    "    #image.transparent('magenta')\n",
    "    return image\n",
    "\n",
    "def alpha_composite(image, mask):\n",
    "    \"\"\" Composite two images together by overriding one opacity channel \"\"\"\n",
    "\n",
    "    compos = pg.Image(mask)\n",
    "    compos.composite(\n",
    "        image,\n",
    "        image.size(),\n",
    "        pg.CompositeOperator.CopyOpacityCompositeOp\n",
    "    )\n",
    "    return compos\n",
    "\n",
    "def remove_background(filename):\n",
    "    \"\"\" Remove the background of the image in 'filename' \"\"\"\n",
    "\n",
    "    img = pg.Image(filename)\n",
    "    transmask = trans_mask_sobel(img)\n",
    "    img = alphacomposite(transmask, img)\n",
    "    img.trim()\n",
    "    img.write('out.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = trans_mask_sobel(path)\n",
    "mask.write('out.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, img in enumerate(cropped):\n",
    "    #2\n",
    "    img_grey = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "    val = filters.threshold_otsu(img_grey)\n",
    "    mask_img = img_grey < val\n",
    "    #1\n",
    "    ret, thresh = cv.threshold(img_grey, 50, 255, cv.THRESH_BINARY)\n",
    " \n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.figure()\n",
    "    plt.imshow(thresh)\n",
    "    plt.figure()\n",
    "    plt.imshow(mask_img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv.Canny(img,100,200)\n",
    "plt.imshow(edges,cmap = 'gray')\n",
    "# Floodfill from point (0, 0)\n",
    "cv.floodFill(im_floodfill, mask, (0,0), 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "F = 11\n",
    "img = temp.copy()\n",
    "#img = cv.imread(path)\n",
    "#img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "img = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "#img = 255 - img\n",
    "plt.imshow(img,cmap = 'gray')\n",
    "sob = cv.Sobel(img, cv.CV_16S,1,1,ksize=11)\n",
    "sob = np.absolute(sob)\n",
    "sob = np.uint8(sob)\n",
    "plt.figure()\n",
    "plt.imshow(sob,cmap = 'gray')\n",
    "blur = cv.GaussianBlur(sob,(F,F),0)\n",
    "plt.figure()\n",
    "plt.imshow(blur,cmap = 'gray')\n",
    "ret, thresh = cv.threshold(blur, 50, 255, cv.THRESH_BINARY)\n",
    "plt.figure()\n",
    "plt.imshow(thresh,cmap = 'gray')\n",
    "adap = cv.adaptiveThreshold(blur,255,cv.ADAPTIVE_THRESH_MEAN_C,cv.THRESH_BINARY,7,2)\n",
    "plt.figure()\n",
    "plt.imshow(adap,cmap = 'gray')\n",
    "\n",
    "im_floodfill = blur.copy()\n",
    "# Notice the size needs to be 2 pixels than the image.\n",
    "h, w = img.shape[:2]\n",
    "mask = np.zeros((h+2, w+2), np.uint8)\n",
    "# Floodfill from point (0, 0)\n",
    "cv.floodFill(im_floodfill, mask, (w-1,h-1), 255)\n",
    "# Invert floodfilled image\n",
    "im_floodfill_inv = cv.bitwise_not(im_floodfill)\n",
    "# Combine the two images to get the foreground.\n",
    "im_out = thresh | im_floodfill_inv\n",
    "plt.figure()\n",
    "plt.imshow(im_out,cmap = 'gray')\n",
    "\n",
    "plt.figure()\n",
    "forg = cv.bitwise_and(temp,temp,mask=im_out)\n",
    "plt.imshow(forg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh.argmax()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
